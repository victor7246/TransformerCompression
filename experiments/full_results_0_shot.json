{
    "arc_challenge": {
        "acc,none": 0.1885665529010239,
        "acc_stderr,none": 0.011430897647675749,
        "acc_norm,none": 0.24658703071672355,
        "acc_norm_stderr,none": 0.012595726268789992,
        "alias": "arc_challenge"
    },
    "arc_easy": {
        "acc,none": 0.3686868686868687,
        "acc_stderr,none": 0.009899640855681058,
        "acc_norm,none": 0.3446969696969697,
        "acc_norm_stderr,none": 0.009752321586569631,
        "alias": "arc_easy"
    },
    "hellaswag": {
        "acc,none": 0.280920135431189,
        "acc_stderr,none": 0.004485300194072218,
        "acc_norm,none": 0.29884485162318264,
        "acc_norm_stderr,none": 0.004568161710399424,
        "alias": "hellaswag"
    },
    "mmlu_abstract_algebra": {
        "alias": "abstract_algebra",
        "acc,none": 0.21,
        "acc_stderr,none": 0.040936018074033236
    },
    "mmlu_business_ethics": {
        "alias": "business_ethics",
        "acc,none": 0.3,
        "acc_stderr,none": 0.04605661864718382
    },
    "mmlu_college_computer_science": {
        "alias": "college_computer_science",
        "acc,none": 0.26,
        "acc_stderr,none": 0.0440844002276808
    },
    "mmlu_college_mathematics": {
        "alias": "college_mathematics",
        "acc,none": 0.21,
        "acc_stderr,none": 0.040936018074033236
    },
    "mmlu_conceptual_physics": {
        "alias": "conceptual_physics",
        "acc,none": 0.26382978723404255,
        "acc_stderr,none": 0.028809989854102946
    },
    "mmlu_formal_logic": {
        "alias": "formal_logic",
        "acc,none": 0.2777777777777778,
        "acc_stderr,none": 0.04006168083848877
    },
    "mmlu_global_facts": {
        "alias": "global_facts",
        "acc,none": 0.18,
        "acc_stderr,none": 0.03861229196653691
    },
    "mmlu_machine_learning": {
        "alias": "machine_learning",
        "acc,none": 0.32142857142857145,
        "acc_stderr,none": 0.04432804055291519
    },
    "mmlu_miscellaneous": {
        "alias": "miscellaneous",
        "acc,none": 0.2413793103448276,
        "acc_stderr,none": 0.015302380123542047
    },
    "mmlu_philosophy": {
        "alias": "philosophy",
        "acc,none": 0.1864951768488746,
        "acc_stderr,none": 0.022122439772480733
    },
    "piqa": {
        "acc,none": 0.6066376496191512,
        "acc_stderr,none": 0.011397418546689315,
        "acc_norm,none": 0.5957562568008705,
        "acc_norm_stderr,none": 0.011449891763007486,
        "alias": "piqa"
    },
    "winogrande": {
        "acc,none": 0.5224940805051302,
        "acc_stderr,none": 0.014038257824059859,
        "alias": "winogrande"
    }
}